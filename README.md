# KMHaS Korean Hate Speech Multiâ€‘Label Classification

í•œêµ­ì–´ í˜ì˜¤ ë°œì–¸(Korean Hate Speech)ì„ **ë©€í‹°ë¼ë²¨ ë¶„ë¥˜(Multiâ€‘Label Classification)** ë°©ì‹ìœ¼ë¡œ íƒì§€í•˜ëŠ” íŒŒì¸íŠœë‹ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.
FastCampus AI Labs ê³¼ì œ ë° ê°œì¸ ì‹¤í—˜ìš©ìœ¼ë¡œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, **KMHaS ë°ì´í„°ì…‹ + ELECTRA ê³„ì—´ ëª¨ë¸**ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

---

## ğŸ“Œ Git Repository
https://github.com/premomo/Korean_Hate_Speech_Tuning
---

## ğŸ“Œ Project Overview

* **Task**: Korean Hate Speech Multiâ€‘Label Classification
* **Dataset**: KMHaS (jeanlee/kmhas_korean_hate_speech)
* **Base Models**:

  * `beomi/KcELECTRA-base-v2022`
  * `monologg/koelectra`
  * `snunlp/KR-Medium`
* **Framework**: PyTorch + HuggingFace Transformers
* **Loss**: `BCEWithLogitsLoss`
* **Evaluation**: Micro / Macro F1, Accuracy (flatten ê¸°ì¤€)

---

## ğŸ§  Labels (8â€‘Class Multiâ€‘Label)

| Index | English   | Korean    |
| ----: | --------- | --------- |
|     0 | origin    | ì¶œì‹ /ì´ì£¼ë¯¼ í˜ì˜¤ |
|     1 | physical  | ì™¸ëª¨ ë¹„í•˜     |
|     2 | politics  | ì •ì¹˜/ì´ë… í˜ì˜¤  |
|     3 | profanity | ì¼ë°˜ ìš•ì„¤     |
|     4 | age       | ì—°ë ¹ ë¹„í•˜     |
|     5 | gender    | ì„±ë³„ í˜ì˜¤     |
|     6 | race      | ì¸ì¢… í˜ì˜¤     |
|     7 | religion  | ì¢…êµ í˜ì˜¤     |

> í•˜ë‚˜ì˜ ë¬¸ì¥ì— **ë³µìˆ˜ ë¼ë²¨ì´ ë™ì‹œì— í™œì„±í™”**ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€ train_kmhas_multilabel_v5.py     # ë©”ì¸ í•™ìŠµ/ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€ Model_Compare.ipynb             # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
â”œâ”€ Multi_label_fine_tuning_*.ipynb # ëª¨ë¸ë³„ ì‹¤í—˜ ë…¸íŠ¸ë¶
â”œâ”€ project/
â”‚  â””â”€ kmhas_kcelectra_multilabel_v5/
â”‚     â”œâ”€ config.json
â”‚     â”œâ”€ pytorch_model.bin
â”‚     â”œâ”€ tokenizer.json
â”‚     â””â”€ meta.json                 # ì‹¤í—˜ ë©”íƒ€ë°ì´í„° & threshold
â””â”€ README.md
```

---

## âš™ï¸ Training Configuration (v5)

```text
Model           : beomi/KcELECTRA-base-v2022
Epochs          : 4
Learning Rate   : 3e-5
Train Batch     : 32
Eval Batch      : 32
Max Length      : 128
Scheduler       : Cosine + Warmup
Warmup Ratio    : 0.1
Seed            : 42
```

* **LR Scheduler**: `cosine` (linearë¡œ êµì²´ ê°€ëŠ¥)
* **Threshold Tuning**: Labelâ€‘wise F1 ìµœì í™”

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Install Dependencies

```bash
pip install torch transformers datasets scikit-learn
```

### 2ï¸âƒ£ Train Model

```python
DO_TRAIN = True
python train_kmhas_multilabel_v5.py
```

### 3ï¸âƒ£ Load & Inference

```python
DO_TRAIN = False
python train_kmhas_multilabel_v5.py
```

---

## ğŸ” Inference Example

```python
text = "í•œêµ­ ë‚¨ìë“¤ì€ ë„ˆë¬´ í˜ì˜¤ìŠ¤ëŸ½ë‹¤"
detected, latency_ms = infer(text)
```

Output:

```
ê²€ì¶œ ë¼ë²¨:
- ì„±ë³„ í˜ì˜¤ : 0.91
- ì¼ë°˜ ìš•ì„¤ : 0.84
ì¶”ë¡  ì‹œê°„(ms): 12.3
```

> ThresholdëŠ” validation ê¸°ì¤€ìœ¼ë¡œ **ë¼ë²¨ë³„ ê°œë³„ íŠœë‹**ë˜ì–´ ì ìš©ë©ë‹ˆë‹¤.

---

## ğŸ“Š Evaluation Strategy

* **Flatten ë°©ì‹ í‰ê°€**

  * ëª¨ë“  ë¼ë²¨ì„ 1D ë²¡í„°ë¡œ í¼ì³ Micro / Macro F1 ê³„ì‚°
* **Baseline**: threshold = 0.5
* **Improved**: threshold grid search (0.05 ~ 0.95)

`meta.json`ì— ë‹¤ìŒ ì •ë³´ê°€ ìë™ ì €ì¥ë©ë‹ˆë‹¤:

* ì‹¤í—˜ ì„¤ì •
* Best epoch metrics
* Tuned threshold
* Tuned metrics

---

## ğŸ§ª Experiments

* v1 ~ v3: LR / Epoch ë¹„êµ
* v4: Batch size 64 (ì†ë„ ì´ìŠˆë¡œ ì¤‘ë‹¨)
* **v5**: Batch 32 + Cosine Scheduler + Threshold Tuning

---

## ğŸ¯ Notes

* í˜ì˜¤ ë°œì–¸ íƒì§€ëŠ” **ë¬¸ë§¥ ì˜ì¡´ì **ì´ë©°, ë°ì´í„° íŠ¹ì„±ìƒ false positive ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.
* ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‹œ:

  * ruleâ€‘based filter ë³‘í–‰
  * confidence score ê¸°ë°˜ UX ì„¤ê³„ ê¶Œì¥

---

## ğŸ“œ License & Disclaimer

* Dataset: KMHaS (ì—°êµ¬/êµìœ¡ ëª©ì )
* ë³¸ í”„ë¡œì íŠ¸ëŠ” **ì—°êµ¬ ë° í•™ìŠµ ëª©ì **ì´ë©°, ì‹¤ì œ ì„œë¹„ìŠ¤ ì ìš© ì‹œ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.

---

## ğŸ‘¤ Author

* **Fast Campus Team 2**
  FastCampus AI Labs



